/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_ACCEL_TCG_GENERATED_TRACERS_H
#define TRACE_ACCEL_TCG_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_EXEC_TB_EVENT;
extern TraceEvent _TRACE_EXEC_TB_NOCACHE_EVENT;
extern TraceEvent _TRACE_EXEC_TB_EXIT_EVENT;
extern TraceEvent _TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS_EVENT;
extern TraceEvent _TRACE_MEMORY_NOTDIRTY_SET_DIRTY_EVENT;
extern TraceEvent _TRACE_TRANSLATE_BLOCK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM2_FALLBACK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM4_FALLBACK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM8_FALLBACK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM16_FALLBACK_EVENT;
extern TraceEvent _TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK_EVENT;
extern TraceEvent _TRACE_STORE_ATOM2_FALLBACK_EVENT;
extern TraceEvent _TRACE_STORE_ATOM4_FALLBACK_EVENT;
extern TraceEvent _TRACE_STORE_ATOM8_FALLBACK_EVENT;
extern TraceEvent _TRACE_STORE_ATOM16_FALLBACK_EVENT;
extern uint16_t _TRACE_EXEC_TB_DSTATE;
extern uint16_t _TRACE_EXEC_TB_NOCACHE_DSTATE;
extern uint16_t _TRACE_EXEC_TB_EXIT_DSTATE;
extern uint16_t _TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS_DSTATE;
extern uint16_t _TRACE_MEMORY_NOTDIRTY_SET_DIRTY_DSTATE;
extern uint16_t _TRACE_TRANSLATE_BLOCK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM2_FALLBACK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM4_FALLBACK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM8_FALLBACK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM16_FALLBACK_DSTATE;
extern uint16_t _TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK_DSTATE;
extern uint16_t _TRACE_STORE_ATOM2_FALLBACK_DSTATE;
extern uint16_t _TRACE_STORE_ATOM4_FALLBACK_DSTATE;
extern uint16_t _TRACE_STORE_ATOM8_FALLBACK_DSTATE;
extern uint16_t _TRACE_STORE_ATOM16_FALLBACK_DSTATE;
#define TRACE_EXEC_TB_ENABLED 1
#define TRACE_EXEC_TB_NOCACHE_ENABLED 1
#define TRACE_EXEC_TB_EXIT_ENABLED 1
#define TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS_ENABLED 1
#define TRACE_MEMORY_NOTDIRTY_SET_DIRTY_ENABLED 1
#define TRACE_TRANSLATE_BLOCK_ENABLED 1
#define TRACE_LOAD_ATOM2_FALLBACK_ENABLED 1
#define TRACE_LOAD_ATOM4_FALLBACK_ENABLED 1
#define TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK_ENABLED 1
#define TRACE_LOAD_ATOM8_FALLBACK_ENABLED 1
#define TRACE_LOAD_ATOM16_FALLBACK_ENABLED 1
#define TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK_ENABLED 1
#define TRACE_STORE_ATOM2_FALLBACK_ENABLED 1
#define TRACE_STORE_ATOM4_FALLBACK_ENABLED 1
#define TRACE_STORE_ATOM8_FALLBACK_ENABLED 1
#define TRACE_STORE_ATOM16_FALLBACK_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_EXEC_TB_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_EXEC_TB) || \
    false)

static inline void _nocheck__trace_exec_tb(void * tb, uintptr_t pc)
{
    if (trace_event_get_state(TRACE_EXEC_TB) && qemu_loglevel_mask(LOG_TRACE)) {
#line 5 "../accel/tcg/trace-events"
        qemu_log("exec_tb " "tb:%p pc=0x%"PRIxPTR "\n", tb, pc);
#line 69 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_exec_tb(void * tb, uintptr_t pc)
{
    if (true) {
        _nocheck__trace_exec_tb(tb, pc);
    }
}

#define TRACE_EXEC_TB_NOCACHE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_EXEC_TB_NOCACHE) || \
    false)

static inline void _nocheck__trace_exec_tb_nocache(void * tb, uintptr_t pc)
{
    if (trace_event_get_state(TRACE_EXEC_TB_NOCACHE) && qemu_loglevel_mask(LOG_TRACE)) {
#line 6 "../accel/tcg/trace-events"
        qemu_log("exec_tb_nocache " "tb:%p pc=0x%"PRIxPTR "\n", tb, pc);
#line 89 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_exec_tb_nocache(void * tb, uintptr_t pc)
{
    if (true) {
        _nocheck__trace_exec_tb_nocache(tb, pc);
    }
}

#define TRACE_EXEC_TB_EXIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_EXEC_TB_EXIT) || \
    false)

static inline void _nocheck__trace_exec_tb_exit(void * last_tb, unsigned int flags)
{
    if (trace_event_get_state(TRACE_EXEC_TB_EXIT) && qemu_loglevel_mask(LOG_TRACE)) {
#line 7 "../accel/tcg/trace-events"
        qemu_log("exec_tb_exit " "tb:%p flags=0x%x" "\n", last_tb, flags);
#line 109 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_exec_tb_exit(void * last_tb, unsigned int flags)
{
    if (true) {
        _nocheck__trace_exec_tb_exit(last_tb, flags);
    }
}

#define TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS) || \
    false)

static inline void _nocheck__trace_memory_notdirty_write_access(uint64_t vaddr, uint64_t ram_addr, unsigned size)
{
    if (trace_event_get_state(TRACE_MEMORY_NOTDIRTY_WRITE_ACCESS) && qemu_loglevel_mask(LOG_TRACE)) {
#line 10 "../accel/tcg/trace-events"
        qemu_log("memory_notdirty_write_access " "0x%" PRIx64 " ram_addr 0x%" PRIx64 " size %u" "\n", vaddr, ram_addr, size);
#line 129 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_memory_notdirty_write_access(uint64_t vaddr, uint64_t ram_addr, unsigned size)
{
    if (true) {
        _nocheck__trace_memory_notdirty_write_access(vaddr, ram_addr, size);
    }
}

#define TRACE_MEMORY_NOTDIRTY_SET_DIRTY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_MEMORY_NOTDIRTY_SET_DIRTY) || \
    false)

static inline void _nocheck__trace_memory_notdirty_set_dirty(uint64_t vaddr)
{
    if (trace_event_get_state(TRACE_MEMORY_NOTDIRTY_SET_DIRTY) && qemu_loglevel_mask(LOG_TRACE)) {
#line 11 "../accel/tcg/trace-events"
        qemu_log("memory_notdirty_set_dirty " "0x%" PRIx64 "\n", vaddr);
#line 149 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_memory_notdirty_set_dirty(uint64_t vaddr)
{
    if (true) {
        _nocheck__trace_memory_notdirty_set_dirty(vaddr);
    }
}

#define TRACE_TRANSLATE_BLOCK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_TRANSLATE_BLOCK) || \
    false)

static inline void _nocheck__trace_translate_block(void * tb, uintptr_t pc, const void * tb_code)
{
    if (trace_event_get_state(TRACE_TRANSLATE_BLOCK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 14 "../accel/tcg/trace-events"
        qemu_log("translate_block " "tb:%p, pc:0x%"PRIxPTR", tb_code:%p" "\n", tb, pc, tb_code);
#line 169 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_translate_block(void * tb, uintptr_t pc, const void * tb_code)
{
    if (true) {
        _nocheck__trace_translate_block(tb, pc, tb_code);
    }
}

#define TRACE_LOAD_ATOM2_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM2_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom2_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM2_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 17 "../accel/tcg/trace-events"
        qemu_log("load_atom2_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 189 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom2_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom2_fallback(memop, ra);
    }
}

#define TRACE_LOAD_ATOM4_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM4_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom4_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM4_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 18 "../accel/tcg/trace-events"
        qemu_log("load_atom4_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 209 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom4_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom4_fallback(memop, ra);
    }
}

#define TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom8_or_exit_fallback(uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM8_OR_EXIT_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 19 "../accel/tcg/trace-events"
        qemu_log("load_atom8_or_exit_fallback " "ra:0x%"PRIxPTR"" "\n", ra);
#line 229 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom8_or_exit_fallback(uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom8_or_exit_fallback(ra);
    }
}

#define TRACE_LOAD_ATOM8_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM8_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom8_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM8_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 20 "../accel/tcg/trace-events"
        qemu_log("load_atom8_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 249 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom8_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom8_fallback(memop, ra);
    }
}

#define TRACE_LOAD_ATOM16_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM16_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom16_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM16_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 21 "../accel/tcg/trace-events"
        qemu_log("load_atom16_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 269 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom16_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom16_fallback(memop, ra);
    }
}

#define TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK) || \
    false)

static inline void _nocheck__trace_load_atom16_or_exit_fallback(uintptr_t ra)
{
    if (trace_event_get_state(TRACE_LOAD_ATOM16_OR_EXIT_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 22 "../accel/tcg/trace-events"
        qemu_log("load_atom16_or_exit_fallback " "ra:0x%"PRIxPTR"" "\n", ra);
#line 289 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_load_atom16_or_exit_fallback(uintptr_t ra)
{
    if (true) {
        _nocheck__trace_load_atom16_or_exit_fallback(ra);
    }
}

#define TRACE_STORE_ATOM2_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STORE_ATOM2_FALLBACK) || \
    false)

static inline void _nocheck__trace_store_atom2_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_STORE_ATOM2_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 23 "../accel/tcg/trace-events"
        qemu_log("store_atom2_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 309 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_store_atom2_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_store_atom2_fallback(memop, ra);
    }
}

#define TRACE_STORE_ATOM4_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STORE_ATOM4_FALLBACK) || \
    false)

static inline void _nocheck__trace_store_atom4_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_STORE_ATOM4_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 24 "../accel/tcg/trace-events"
        qemu_log("store_atom4_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 329 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_store_atom4_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_store_atom4_fallback(memop, ra);
    }
}

#define TRACE_STORE_ATOM8_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STORE_ATOM8_FALLBACK) || \
    false)

static inline void _nocheck__trace_store_atom8_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_STORE_ATOM8_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 25 "../accel/tcg/trace-events"
        qemu_log("store_atom8_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 349 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_store_atom8_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_store_atom8_fallback(memop, ra);
    }
}

#define TRACE_STORE_ATOM16_FALLBACK_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_STORE_ATOM16_FALLBACK) || \
    false)

static inline void _nocheck__trace_store_atom16_fallback(uint32_t memop, uintptr_t ra)
{
    if (trace_event_get_state(TRACE_STORE_ATOM16_FALLBACK) && qemu_loglevel_mask(LOG_TRACE)) {
#line 26 "../accel/tcg/trace-events"
        qemu_log("store_atom16_fallback " "mop:0x%"PRIx32", ra:0x%"PRIxPTR"" "\n", memop, ra);
#line 369 "trace/trace-accel_tcg.h"
    }
}

static inline void trace_store_atom16_fallback(uint32_t memop, uintptr_t ra)
{
    if (true) {
        _nocheck__trace_store_atom16_fallback(memop, ra);
    }
}
#endif /* TRACE_ACCEL_TCG_GENERATED_TRACERS_H */
